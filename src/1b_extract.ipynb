{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract text and images (Classical Chinese)\n",
    "\n",
    "This file identifies the text lines manually labelled in Transkribus. It saves individual lines as text and images to different files, which can then be used to create a HF dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "from PIL import Image, ImageDraw\n",
    "import pandas as pd\n",
    "import glob\n",
    "import itertools\n",
    "import unicodedata\n",
    "import os "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory: c:\\Users\\alexm\\NUS Dropbox\\Alexander Mozdzen\\ocr\\gongguan-ocr-1\\src\n"
     ]
    }
   ],
   "source": [
    "cwd = os.getcwd()\n",
    "print(f\"Current working directory: {cwd}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_folder = \"../data\"\n",
    "input_folders = [\n",
    "    f\"{output_folder}/1_11\",\n",
    "    f\"{output_folder}/12_21\", \n",
    "    f\"{output_folder}/22_31\",\n",
    "    f\"{output_folder}/32_41\"\n",
    "]\n",
    "text_output_folder = f\"{output_folder}/texts\"\n",
    "image_output_folder = f\"{output_folder}/images\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_chinese_text(text):\n",
    "    \"\"\"\n",
    "    Normalize text to standard Chinese Unicode form.\n",
    "    Converts variant Unicode characters (e.g., Kangxi Radicals) into normal forms.\n",
    "    \"\"\"\n",
    "    return unicodedata.normalize(\"NFKC\", text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "New version that uses the included index in the XML file for the reading order of the text lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#parse XML with index ordering using list comprehension\n",
    "def parse_xml_index_ordering(file_path):\n",
    "    tree = ET.parse(file_path)\n",
    "    root = tree.getroot()\n",
    "    namespace = {'ns': 'http://schema.primaresearch.org/PAGE/gts/pagecontent/2013-07-15'}\n",
    "\n",
    "    regions = []\n",
    "\n",
    "    # Iterate over TextRegion elements\n",
    "    for text_region in root.findall(\".//ns:TextRegion\", namespace):\n",
    "        region_id = text_region.get(\"id\")\n",
    "        coords_elem = text_region.find(\"ns:Coords\", namespace)\n",
    "\n",
    "        if coords_elem is None:\n",
    "            continue\n",
    "\n",
    "        # Extract TextLines with their indices using list comprehension\n",
    "        text_lines = [\n",
    "            (normalize_chinese_text(line.find(\".//ns:Unicode\", namespace).text),  # Normalized text content\n",
    "             int(line.get(\"custom\").split(\"{index:\")[1].split(\";}\")[0]))  # The index number\n",
    "            for line in text_region.findall(\".//ns:TextLine\", namespace)\n",
    "            if line.find(\".//ns:Unicode\", namespace) is not None\n",
    "        ]\n",
    "        \n",
    "        if not text_lines:\n",
    "            continue  # Skip empty regions\n",
    "        \n",
    "        # Sort text lines by index\n",
    "        text_lines.sort(key=lambda x: x[1])\n",
    "        \n",
    "        # Extract just the text in order\n",
    "        ordered_text = \" \".join(text for text, _ in text_lines)\n",
    "        \n",
    "        # Extract coordinates\n",
    "        coords_str = coords_elem.get(\"points\")\n",
    "        regions.append((region_id, coords_str, ordered_text))\n",
    "\n",
    "    return regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw each text line with buffer and save as image\n",
    "def create_images_from_regions(page_name, image_path, regions, buffer_above=10, buffer_below=10, buffer_left=10, buffer_right=10):\n",
    "    data = []\n",
    "    image = Image.open(image_path)\n",
    "\n",
    "    for idx, (region_id, coords_str, region_text) in enumerate(regions):\n",
    "        # Parse the coordinates and find the bounding box\n",
    "        points = [tuple(map(int, point.split(','))) for point in coords_str.split()]\n",
    "        \n",
    "        x_coords = [p[0] for p in points]\n",
    "        y_coords = [p[1] for p in points]\n",
    "\n",
    "        min_x, max_x = min(x_coords) - buffer_left, max(x_coords) + buffer_right\n",
    "        min_y, max_y = min(y_coords) - buffer_above, max(y_coords) + buffer_below\n",
    "\n",
    "        # Crop the image to the bounding box\n",
    "        cropped_image = image.crop((min_x, min_y, max_x, max_y))\n",
    "\n",
    "        # Append the identifier and text to the data list\n",
    "        data.append([region_text, f'{page_name}_{region_id}'])\n",
    "\n",
    "        # Save text data to a CSV file\n",
    "        df = pd.DataFrame(data, columns=['text', 'identifier'])\n",
    "        df.to_csv(f'{text_output_folder}/{page_name}.csv', index=False)\n",
    "\n",
    "        # Save the cropped image\n",
    "        cropped_image.save(f'{image_output_folder}/{page_name}_{region_id}.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code extracts the coordinates of the text regions from the xml files and crops them into individual images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for xml_file_path in glob.glob(f\"{input_folder}/page/*.xml\"):\n",
    "    # Normalize path and convert backslashes to forward slashes\n",
    "    xml_file_path = os.path.normpath(xml_file_path).replace(\"\\\\\", \"/\")\n",
    "    page_name = xml_file_path.split(\"/\")[-1].replace(\".xml\", \"\")\n",
    "    image_file_path = f\"{input_folder}/{page_name}.jpg\" \n",
    "\n",
    "    # Parse XML and extract text regions\n",
    "    regions = parse_xml_index_ordering(xml_file_path)\n",
    "\n",
    "    # Create images from the text regions\n",
    "    create_images_from_regions(page_name, image_file_path, regions, buffer_above=0, buffer_below=0, buffer_left=0, buffer_right=0)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
